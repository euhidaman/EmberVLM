# EmberVLM Training Configuration
# Hyperparameters for all training stages

# Global training settings
global:
  seed: 42
  mixed_precision: "bf16"
  gradient_clipping: 1.0
  dataloader_num_workers: 8
  pin_memory: true
  use_cache: false

# Hardware configuration
hardware:
  num_gpus: 2
  gpu_type: "A100-80GB"
  distributed_backend: "nccl"
  use_fsdp: true
  use_gradient_checkpointing: true

# Monitoring & Logging
monitoring:
  wandb:
    project: "EmberVLM"
    entity: null  # Set to your WandB entity
    log_every_n_steps: 10
    save_every_n_steps: 500

  codecarbon:
    enabled: true
    log_level: "info"
    emissions_endpoint: null

  checkpointing:
    save_steps: 500
    save_total_limit: 2  # Keep only latest 2 checkpoints
    overwrite_on_hub: true

# HuggingFace Hub settings
huggingface:
  hub_model_id: "embervlm/EmberVLM"
  push_to_hub: true
  private: false

# Stage 0: Dataset Preparation
stage0_data_prep:
  enabled: true
  subsample_ratio: 0.2  # Use 20% of each dataset
  datasets:
    coco_captions:
      enabled: true
      split: "train"
      max_samples: 24000  # 20% of 118K
    flickr30k:
      enabled: true
      max_samples: 6200  # 20% of 31K
    llava_instruct:
      enabled: true
      max_samples: 30000  # 20% of 150K
    vqa_v2:
      enabled: true
      max_samples: 130000  # 20% of 650K
  output_dir: "data/processed"

# Stage 1: Vision-Language Alignment
stage1_alignment:
  enabled: true
  num_epochs: 1
  samples: 500_000

  # Batch settings
  batch_size_per_gpu: 128
  gradient_accumulation_steps: 4
  effective_batch_size: 1024  # 128 * 2 GPUs * 4 accum

  # Optimizer settings
  optimizer: "adamw"
  learning_rate: 3.0e-4
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8

  # Scheduler
  scheduler: "cosine"
  warmup_ratio: 0.05
  min_lr_ratio: 0.1

  # Loss weights
  losses:
    contrastive: 0.5
    captioning: 0.5

  # Metrics to track
  metrics:
    - "clip_score"
    - "cider"
    - "perplexity"

# Stage 2: Multimodal Instruction Tuning
stage2_instruction:
  enabled: true
  num_epochs: 2
  samples: 300_000

  # Batch settings (smaller due to teacher model)
  batch_size_per_gpu: 64
  gradient_accumulation_steps: 4
  effective_batch_size: 512

  # Optimizer settings
  optimizer: "adamw"
  learning_rate: 1.0e-4
  weight_decay: 0.01

  # Scheduler
  scheduler: "linear"
  warmup_ratio: 0.1

  # Knowledge Distillation
  distillation:
    enabled: true
    teacher_model: "Qwen/Qwen-VL-Chat"
    temperature: 2.0

  # Loss weights
  losses:
    task_loss: 0.4
    logit_distillation: 0.3
    hidden_state_distillation: 0.2
    attention_distillation: 0.1

  # Metrics
  metrics:
    - "accuracy"
    - "bleu_4"
    - "rouge_l"

# Stage 3: Specialized Reasoning Finetuning
stage3_reasoning:
  enabled: true
  num_epochs: 3

  # Batch settings
  batch_size_per_gpu: 32
  gradient_accumulation_steps: 8
  effective_batch_size: 512

  # Optimizer settings
  optimizer: "adamw"
  learning_rate: 5.0e-5
  weight_decay: 0.01

  # Scheduler
  scheduler: "cosine"
  warmup_ratio: 0.05

  # Curriculum Learning
  curriculum:
    epoch_1: "single_robot"  # Easy
    epoch_2: "multi_robot"   # Medium
    epoch_3: "incident_response"  # Hard

  # Batch composition
  batch_composition:
    robot_selection: 0.5
    incident_response: 0.3
    general_vqa: 0.2  # Prevent catastrophic forgetting

  # Loss weights
  losses:
    cross_entropy: 0.6
    reasoning_fidelity: 0.25
    action_coherence: 0.15

  # Chain-of-Thought settings
  cot:
    enabled: true
    max_reasoning_steps: 6

  # Metrics
  metrics:
    - "robot_selection_accuracy"
    - "robot_selection_f1"
    - "action_plan_quality"
    - "reasoning_coherence"

# Stage 4: RLHF (Optional)
stage4_rlhf:
  enabled: false  # Optional stage
  num_epochs: 1

  # Batch settings
  batch_size_per_gpu: 16
  gradient_accumulation_steps: 8

  # PPO settings
  ppo:
    learning_rate: 1.0e-5
    kl_penalty: 0.01
    clip_range: 0.2
    value_loss_coef: 0.5
    entropy_coef: 0.01

  # Reward model
  reward_model:
    safety_weight: 0.4
    efficiency_weight: 0.3
    success_weight: 0.3

  # Preference data
  preference_pairs: 10_000

# Evaluation settings
evaluation:
  eval_every_n_steps: 1000
  samples_per_eval: 500

  benchmarks:
    robot_selection:
      enabled: true
      test_samples: 500
    incident_response:
      enabled: true
      metrics: ["success_rate", "efficiency", "safety"]
    vqa_v2:
      enabled: true
      split: "test-dev"
    coco_captioning:
      enabled: true
      metrics: ["cider", "spice"]
    ok_vqa:
      enabled: true

# Carbon budget
carbon_budget:
  max_total_kg_co2: 50
  alert_threshold_per_hour: 5
  enable_dynamic_batch_sizing: true

